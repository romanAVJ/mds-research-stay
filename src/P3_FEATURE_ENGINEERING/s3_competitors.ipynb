{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitors\n",
    "\n",
    "30 June, 2024\n",
    "\n",
    "@roman\n",
    "\n",
    "Code to find neighbors of a given competitor for each property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from tqdm import tqdm\n",
    "import h3\n",
    "import os\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "import scipy.sparse as sp\n",
    "from scipy import io\n",
    "from sklearn.cluster import MiniBatchKMeans, SpectralClustering, HDBSCAN\n",
    "from INEGIpy import MarcoGeoestadistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# show 100 columns in pandas\n",
    "pd.set_option('display.max_columns', 100)\n",
    "geo_framework = MarcoGeoestadistico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 852931 entries, 0 to 853032\n",
      "Data columns (total 42 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   property_id                    852931 non-null  object        \n",
      " 1   valor_fisico_construccion      852931 non-null  float64       \n",
      " 2   id_avaluo                      852931 non-null  object        \n",
      " 3   fecha_avaluo                   852931 non-null  datetime64[ns]\n",
      " 4   colonia                        852931 non-null  object        \n",
      " 5   id_clase_inmueble              852931 non-null  int64         \n",
      " 6   id_tipo_inmueble               852931 non-null  int64         \n",
      " 7   conservacion                   852931 non-null  float64       \n",
      " 8   elevador                       824560 non-null  float64       \n",
      " 9   niveles                        852931 non-null  int64         \n",
      " 10  cve_ref_proximidad_urbana      852931 non-null  int64         \n",
      " 11  cve_nivel_equipamiento_urbano  852931 non-null  int64         \n",
      " 12  valor_mercado                  852931 non-null  int64         \n",
      " 13  valor_concluido_total          852931 non-null  int64         \n",
      " 14  nivel                          852931 non-null  int64         \n",
      " 15  unidades_rentables             852931 non-null  object        \n",
      " 16  edad_anios                     852931 non-null  int64         \n",
      " 17  precio_m2                      852931 non-null  int64         \n",
      " 18  vida_util_remanente            852931 non-null  int64         \n",
      " 19  cve_clasificacion_zona         852931 non-null  int64         \n",
      " 20  cve_vigilancia                 536484 non-null  float64       \n",
      " 21  regimen_propiedad              852931 non-null  object        \n",
      " 22  tipo_vialidad                  536484 non-null  float64       \n",
      " 23  id_uv                          852931 non-null  int64         \n",
      " 24  id_municipio                   852931 non-null  object        \n",
      " 25  id_entidad_f                   852931 non-null  object        \n",
      " 26  clave_controlador              852931 non-null  int64         \n",
      " 27  clave_valuador                 852931 non-null  int64         \n",
      " 28  id_otorgante                   852931 non-null  object        \n",
      " 29  cp                             852931 non-null  int64         \n",
      " 30  latitud                        852931 non-null  float64       \n",
      " 31  longitud                       852931 non-null  float64       \n",
      " 32  recamaras                      852931 non-null  int64         \n",
      " 33  banos                          852931 non-null  int64         \n",
      " 34  medio_banos                    852931 non-null  int64         \n",
      " 35  estacionamiento                852931 non-null  int64         \n",
      " 36  superficie_terreno             852931 non-null  int64         \n",
      " 37  superficie_construida          852931 non-null  int64         \n",
      " 38  superficie_accesoria           852931 non-null  int64         \n",
      " 39  superficie_vendible            852931 non-null  int64         \n",
      " 40  valor_fisico_terreno_m2        852931 non-null  float64       \n",
      " 41  geometry                       852931 non-null  geometry      \n",
      "dtypes: datetime64[ns](1), float64(8), geometry(1), int64(24), object(8)\n",
      "memory usage: 279.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# read parquet\n",
    "gdf_properties = pd.read_parquet(\"../../data/interim/cleaned_data_s4.parquet\")\n",
    "\n",
    "# to geopandas\n",
    "gdf_properties = gpd.GeoDataFrame(\n",
    "    gdf_properties,\n",
    "    geometry=gpd.points_from_xy(gdf_properties['longitud'], gdf_properties['latitud']),\n",
    "    crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "# change crs to 6372\n",
    "gdf_properties = gdf_properties.to_crs(\"EPSG:6372\")\n",
    "\n",
    "gdf_properties.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   city_cluster  158 non-null    int64   \n",
      " 1   geometry      158 non-null    geometry\n",
      " 2   id_entidad_f  158 non-null    object  \n",
      " 3   id_municipio  158 non-null    object  \n",
      "dtypes: geometry(1), int64(1), object(2)\n",
      "memory usage: 5.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# read parquet\n",
    "gdf_cities = gpd.read_parquet(\"../../data/misc/polygons_cities_analysis.parquet\")\n",
    "\n",
    "# change crs to 6372\n",
    "gdf_cities = gdf_cities.to_crs(\"EPSG:6372\")\n",
    "\n",
    "gdf_cities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer 1m around the cities to include the properties that are in the border\n",
    "gdf_cities['geometry'] = gdf_cities.buffer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_cluster</th>\n",
       "      <th>geometry</th>\n",
       "      <th>id_entidad_f</th>\n",
       "      <th>id_municipio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2802509.221 807490.857, 2802509.124 ...</td>\n",
       "      <td>09</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((1629955.411 1907388.013, 1629955.308...</td>\n",
       "      <td>26</td>\n",
       "      <td>030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((3774584.759 1040368.498, 3774584.666...</td>\n",
       "      <td>31</td>\n",
       "      <td>050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((1689809.905 1228250.719, 1689809.802...</td>\n",
       "      <td>03</td>\n",
       "      <td>008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((2925744.611 1137556.825, 2925744.525...</td>\n",
       "      <td>28</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_cluster                                           geometry  \\\n",
       "0             0  POLYGON ((2802509.221 807490.857, 2802509.124 ...   \n",
       "1             1  POLYGON ((1629955.411 1907388.013, 1629955.308...   \n",
       "2             2  POLYGON ((3774584.759 1040368.498, 3774584.666...   \n",
       "3             3  POLYGON ((1689809.905 1228250.719, 1689809.802...   \n",
       "4             4  POLYGON ((2925744.611 1137556.825, 2925744.525...   \n",
       "\n",
       "  id_entidad_f id_municipio  \n",
       "0           09          003  \n",
       "1           26          030  \n",
       "2           31          050  \n",
       "3           03          008  \n",
       "4           28          003  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see table\n",
    "gdf_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle\n",
    "gdf_properties = (\n",
    "    gdf_properties\n",
    "    # new vars\n",
    "    .assign(\n",
    "        property_type=lambda x: np.where(x['id_tipo_inmueble'].le(3), 'house', 'apartment'),\n",
    "        longitude=lambda x: x[\"geometry\"].x,\n",
    "        latitude=lambda x: x[\"geometry\"].y,\n",
    "        estacionamiento=lambda x: x[\"estacionamiento\"].fillna(0),\n",
    "        price_per_sqm=lambda x: x[\"valor_mercado\"] / x[\"superficie_vendible\"],\n",
    "        log_price_per_sqm=lambda x: np.log(x[\"price_per_sqm\"]),\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    # categorize variables for comparisson\n",
    "    .assign(\n",
    "        recamaras_cat=lambda x: np.select(\n",
    "            [\n",
    "                x[\"recamaras\"].le(1),\n",
    "                x[\"recamaras\"].le(2),\n",
    "                x[\"recamaras\"].le(3),\n",
    "                x[\"recamaras\"].gt(3),\n",
    "            ],\n",
    "            [\n",
    "                1, 2, 3, 4\n",
    "            ],\n",
    "            default=0\n",
    "        ),\n",
    "        banos_cat=lambda x: np.select(\n",
    "            [\n",
    "                x[\"banos\"].le(1),\n",
    "                x[\"banos\"].le(2),\n",
    "                x[\"banos\"].le(3),\n",
    "                x[\"banos\"].gt(3),\n",
    "            ],\n",
    "            [\n",
    "                1, 2, 3, 4\n",
    "            ],\n",
    "            default=0\n",
    "        ),\n",
    "        niveles_cat=lambda x: \n",
    "            np.where(x['niveles'].le(1), 1, 2),\n",
    "        vida_util_cat=lambda x: np.select(\n",
    "            [\n",
    "                x[\"vida_util_remanente\"].le(30),\n",
    "                x[\"vida_util_remanente\"].le(60),\n",
    "                x[\"vida_util_remanente\"].le(70),\n",
    "                x[\"vida_util_remanente\"].gt(70),\n",
    "            ],\n",
    "            [\n",
    "                1, 2, 3, 4\n",
    "            ],\n",
    "            default=0\n",
    "        ),\n",
    "        elevador_cat=lambda x: \n",
    "            np.where(x['elevador'].lt(1), 0, 1),\n",
    "        estacionamiento_cat=lambda x: np.select(\n",
    "            [\n",
    "                x[\"estacionamiento\"].le(0),\n",
    "                x[\"estacionamiento\"].le(1),\n",
    "                x[\"estacionamiento\"].le(2),\n",
    "                x[\"estacionamiento\"].gt(2),\n",
    "            ],\n",
    "            [\n",
    "                0, 1, 2, 3\n",
    "            ],\n",
    "            default=0\n",
    "        ),\n",
    "    )\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_cluster</th>\n",
       "      <th>geometry</th>\n",
       "      <th>id_entidad_f</th>\n",
       "      <th>id_municipio</th>\n",
       "      <th>area_city_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2802509.221 807490.857, 2802509.124 ...</td>\n",
       "      <td>09</td>\n",
       "      <td>003</td>\n",
       "      <td>2904.067758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((1629955.411 1907388.013, 1629955.308...</td>\n",
       "      <td>26</td>\n",
       "      <td>030</td>\n",
       "      <td>209.597369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((3774584.759 1040368.498, 3774584.666...</td>\n",
       "      <td>31</td>\n",
       "      <td>050</td>\n",
       "      <td>421.999965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((1689809.905 1228250.719, 1689809.802...</td>\n",
       "      <td>03</td>\n",
       "      <td>008</td>\n",
       "      <td>51.848444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((2925744.611 1137556.825, 2925744.525...</td>\n",
       "      <td>28</td>\n",
       "      <td>003</td>\n",
       "      <td>189.096787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_cluster                                           geometry  \\\n",
       "0             0  POLYGON ((2802509.221 807490.857, 2802509.124 ...   \n",
       "1             1  POLYGON ((1629955.411 1907388.013, 1629955.308...   \n",
       "2             2  POLYGON ((3774584.759 1040368.498, 3774584.666...   \n",
       "3             3  POLYGON ((1689809.905 1228250.719, 1689809.802...   \n",
       "4             4  POLYGON ((2925744.611 1137556.825, 2925744.525...   \n",
       "\n",
       "  id_entidad_f id_municipio  area_city_km2  \n",
       "0           09          003    2904.067758  \n",
       "1           26          030     209.597369  \n",
       "2           31          050     421.999965  \n",
       "3           03          008      51.848444  \n",
       "4           28          003     189.096787  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get area of each city\n",
    "gdf_cities[\"area_city_km2\"] = gdf_cities[\"geometry\"].area / 1e+6\n",
    "gdf_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852931, 55)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join data\n",
    "gdf_properties = (\n",
    "    gdf_properties\n",
    "    .sjoin(\n",
    "        gdf_cities.loc[:, [\"city_cluster\", \"geometry\", 'area_city_km2']],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"property_id\"], keep=\"first\")\n",
    "    .drop(columns=[\"index_right\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# see shape\n",
    "gdf_properties.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recamaras_cat</th>\n",
       "      <th>banos_cat</th>\n",
       "      <th>niveles_cat</th>\n",
       "      <th>vida_util_cat</th>\n",
       "      <th>elevador_cat</th>\n",
       "      <th>estacionamiento_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169201.0</td>\n",
       "      <td>104016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49383.0</td>\n",
       "      <td>574765.0</td>\n",
       "      <td>462058.0</td>\n",
       "      <td>14153.0</td>\n",
       "      <td>683730.0</td>\n",
       "      <td>566711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507910.0</td>\n",
       "      <td>199792.0</td>\n",
       "      <td>390873.0</td>\n",
       "      <td>565858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262388.0</td>\n",
       "      <td>55115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33250.0</td>\n",
       "      <td>23259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40352.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recamaras_cat  banos_cat  niveles_cat  vida_util_cat  elevador_cat  \\\n",
       "0            NaN        NaN          NaN            NaN      169201.0   \n",
       "1        49383.0   574765.0     462058.0        14153.0      683730.0   \n",
       "2       507910.0   199792.0     390873.0       565858.0           NaN   \n",
       "3       262388.0    55115.0          NaN       232568.0           NaN   \n",
       "4        33250.0    23259.0          NaN        40352.0           NaN   \n",
       "\n",
       "   estacionamiento_cat  \n",
       "0             104016.0  \n",
       "1             566711.0  \n",
       "2             169035.0  \n",
       "3              13169.0  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see cat vars description\n",
    "(\n",
    "    gdf_properties\n",
    "    .filter(like=\"_cat\")\n",
    "    .apply(pd.Series.value_counts)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many properties didnt join\n",
    "gdf_properties[\"city_cluster\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there is a index repeated\n",
    "gdf_properties.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get Competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1: Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_neighbors_properties(gdf, r=1):\n",
    "    # copy\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # fit kdtree\n",
    "    kdtree = KDTree(\n",
    "        data=gdf[['longitude', 'latitude']],\n",
    "    )\n",
    "\n",
    "    # get neighbors at r-km\n",
    "    return kdtree.query_ball_point(\n",
    "        gdf[['longitude', 'latitude']],\n",
    "        r=r * 1_000,\n",
    "        workers=-1\n",
    "    )\n",
    "\n",
    "def get_possible_neighbors(df_own, df_theirs, vars_list):\n",
    "    return (\n",
    "        df_own\n",
    "        .loc[:, vars_list + ['neighbors_list']]\n",
    "        .explode('neighbors_list')\n",
    "        .rename(columns={'neighbors_list': 'id_neighbor'})\n",
    "        .reset_index()\n",
    "        .merge(\n",
    "            (\n",
    "                df_theirs\n",
    "                .assign(index=lambda x: x.index)\n",
    "                .loc[:, ['index'] + vars_list]\n",
    "                ),\n",
    "            how='inner',\n",
    "            left_on='id_neighbor',\n",
    "            right_on='index',\n",
    "            suffixes=('_own', '_neighbor'),\n",
    "        )\n",
    "        .query(\"property_id_own != property_id_neighbor\")  # remove self\n",
    "    )\n",
    "\n",
    "\n",
    "# get distance\n",
    "def find_competitors(gdf):\n",
    "    # Distance\n",
    "    gdf_distance = (\n",
    "        gdf.copy()\n",
    "        .assign(\n",
    "            # geo distance\n",
    "            geo_distance=lambda x: np.sqrt(np.sqrt(\n",
    "                (x['longitude_own'] - x['longitude_neighbor'])**2\n",
    "                + (x['latitude_own'] - x['latitude_neighbor'])**2\n",
    "            ) / 1e+3),  # normalize to 0-1\n",
    "            # topology distance\n",
    "            terrain_distance=lambda x: np.abs(1-x['superficie_terreno_neighbor'] / x['superficie_terreno_own']).clip(0, 1),\n",
    "            built_distance=lambda x: np.sqrt(np.abs(1-x['superficie_construida_neighbor'] / x['superficie_construida_own']).clip(0, 1)),\n",
    "            # characteristics distance\n",
    "            characteristics_distance=lambda x: np.sqrt(np.sqrt(\n",
    "                (x['elevador_cat_own'] - x['elevador_cat_neighbor'])**2  # 0s & 1s\n",
    "                + (x['niveles_cat_own'] - x['niveles_cat_neighbor'])**2  # 1s & 2s (idem)\n",
    "                + (x['vida_util_cat_own'] - x['vida_util_cat_neighbor'])**2  \n",
    "                + (x['recamaras_cat_own'] - x['recamaras_cat_neighbor'])**2\n",
    "                + (x['banos_cat_own'] - x['banos_cat_neighbor'])**2\n",
    "                + (x['estacionamiento_cat_own'] - x['estacionamiento_cat_neighbor'])**2\n",
    "            ) / (0.5 * np.sqrt(1 + 1 + 3**2 + 3**2 + 3**2 + 3**2))),\n",
    "            # time distance (relu)\n",
    "            time_distance_raw=lambda x: (\n",
    "               (x['fecha_avaluo_own'] - x['fecha_avaluo_neighbor']).dt.days\n",
    "            ),\n",
    "            time_distance=lambda x: np.square(x['time_distance_raw'] / (365 * 2)).clip(0, 1)\n",
    "        )\n",
    "        # filter out those that are more than a year apart\n",
    "        .query(\"time_distance.le(1)\")\n",
    "        .assign(\n",
    "            # total distance\n",
    "            total_distance=lambda x: (\n",
    "                x['geo_distance'] * GEO_WEIGHT\n",
    "                + x['terrain_distance'] * TERRAIN_WEIGHT\n",
    "                + x['built_distance'] * BUILT_WEIGHT\n",
    "                + x['characteristics_distance'] * CHAR_WEIGHT\n",
    "                + x['time_distance'] * TIME_WEIGHT\n",
    "            )\n",
    "        )\n",
    "        # filter all those that are above 1 of distance\n",
    "        # .query(\"total_distance.lt(1)\")\n",
    "        .query(\"total_distance.gt(0)\")  # eliminate 0s in the distance to avoid comparing to itself\n",
    "    )\n",
    "    # Aggregation\n",
    "    df_comps = (\n",
    "        gdf_distance\n",
    "        .assign(\n",
    "            index_distance_tuple=lambda x: list(zip(x['property_id_neighbor'], x['total_distance'])),\n",
    "        )\n",
    "        .groupby('property_id_own', as_index=False)\n",
    "        .agg(\n",
    "            neighbors_list=('index_distance_tuple', list),\n",
    "            num_neighbors=('property_id_neighbor', 'count'),\n",
    "        )\n",
    "    )\n",
    "    return df_comps\n",
    "\n",
    "\n",
    "# function to orchestrate the process\n",
    "def get_competitors(gdf, property_type='apartment', city=0, batch_size=None, radius=1):\n",
    "    # params\n",
    "    cols_to_stay = [\n",
    "        # variables to stay\n",
    "        'property_id',\n",
    "        # geographic\n",
    "        'longitude', 'latitude',\n",
    "        # topology\n",
    "        'superficie_terreno', 'superficie_construida',\n",
    "        # characteristics\n",
    "        'elevador_cat', 'niveles_cat', 'vida_util_cat', \n",
    "        'recamaras_cat', 'banos_cat', 'estacionamiento_cat',\n",
    "        # time\n",
    "        'fecha_avaluo',\n",
    "    ]\n",
    "\n",
    "    # subset \n",
    "    gdf_work = (\n",
    "        gdf\n",
    "        .query(\"city_cluster.eq(@city) & property_type.eq(@property_type)\")\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # check if there are properties\n",
    "    if gdf_work.shape[0] == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # get neighbors\n",
    "    gdf_work['neighbors_list'] = get_neighbors_properties(gdf_work, r=radius)\n",
    "\n",
    "    # get possible neighbors by batch\n",
    "    n_batches = gdf_work.shape[0] // batch_size\n",
    "    if n_batches > 0:\n",
    "        batch_indexes = np.array_split(gdf_work.index, gdf_work.shape[0] // batch_size)\n",
    "    else:\n",
    "        batch_indexes = [gdf_work.index]\n",
    "\n",
    "    gdf_neighbors_list = []\n",
    "    for batch in batch_indexes:\n",
    "        # print batch\n",
    "        # get possible neighbors\n",
    "        gdf_neighbors_info = get_possible_neighbors(\n",
    "            df_own=gdf_work.loc[batch],\n",
    "            df_theirs=gdf_work,\n",
    "            vars_list=cols_to_stay\n",
    "        )\n",
    "        # find competitors\n",
    "        gdf_neighbors_subset = find_competitors(gdf_neighbors_info)\n",
    "        # append\n",
    "        gdf_neighbors_list.append(gdf_neighbors_subset)\n",
    "\n",
    "    # concatenate\n",
    "    gdf_neighbors = pd.concat(gdf_neighbors_list)\n",
    "    \n",
    "    return gdf_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cities:   0%|          | 0/158 [03:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m tqdm(cities_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCities\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m property_type \u001b[38;5;129;01min\u001b[39;00m property_types_list:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# get competitors\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         df_comps \u001b[38;5;241m=\u001b[39m \u001b[43mget_competitors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgdf_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproperty_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperty_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.5\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# search radius in km\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# append\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         df_competitors_list\u001b[38;5;241m.\u001b[39mappend(df_comps)\n",
      "Cell \u001b[0;32mIn[13], line 142\u001b[0m, in \u001b[0;36mget_competitors\u001b[0;34m(gdf, property_type, city, batch_size, radius)\u001b[0m\n\u001b[1;32m    138\u001b[0m gdf_neighbors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_indexes:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# print batch\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# get possible neighbors\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     gdf_neighbors_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_possible_neighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_own\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdf_work\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_theirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdf_work\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvars_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols_to_stay\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# find competitors\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     gdf_neighbors_subset \u001b[38;5;241m=\u001b[39m find_competitors(gdf_neighbors_info)\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mget_possible_neighbors\u001b[0;34m(df_own, df_theirs, vars_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_possible_neighbors\u001b[39m(df_own, df_theirs, vars_list):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m         \u001b[43mdf_own\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvars_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneighbors_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneighbors_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbors_list\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_neighbor\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m     26\u001b[0m             (\n\u001b[1;32m     27\u001b[0m                 df_theirs\n\u001b[1;32m     28\u001b[0m                 \u001b[38;5;241m.\u001b[39massign(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     29\u001b[0m                 \u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m vars_list]\n\u001b[1;32m     30\u001b[0m                 ),\n\u001b[1;32m     31\u001b[0m             how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m             left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_neighbor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     33\u001b[0m             right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m             suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_own\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_neighbor\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperty_id_own != property_id_neighbor\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# remove self\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/frame.py:9827\u001b[0m, in \u001b[0;36mDataFrame.explode\u001b[0;34m(self, column, ignore_index)\u001b[0m\n\u001b[1;32m   9825\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns must have matching element counts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9826\u001b[0m     result \u001b[38;5;241m=\u001b[39m DataFrame({c: df[c]\u001b[38;5;241m.\u001b[39mexplode() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns})\n\u001b[0;32m-> 9827\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   9829\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/frame.py:10730\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10720\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10722\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10723\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10728\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10729\u001b[0m         )\n\u001b[0;32m> 10730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10737\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10738\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/reshape/merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/reshape/merge.py:879\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    877\u001b[0m left\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m llabels\n\u001b[1;32m    878\u001b[0m right\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m rlabels\n\u001b[0;32m--> 879\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/reshape/concat.py:682\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    680\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 682\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    686\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/internals/concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/internals/concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[0;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[1;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    221\u001b[0m             axes[i],\n\u001b[1;32m    222\u001b[0m             indexers[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[0;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/internals/managers.py:594\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 594\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/internals/managers.py:364\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    367\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mds-research-stay/lib/python3.10/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get competitors\n",
    "# city values\n",
    "cities_list = gdf_properties['city_cluster'].sort_values().unique()\n",
    "property_types_list = gdf_properties['property_type'].unique()\n",
    "\n",
    "# params\n",
    "GEO_WEIGHT = 0.1\n",
    "TERRAIN_WEIGHT = 0.1\n",
    "BUILT_WEIGHT = 0.3\n",
    "CHAR_WEIGHT = 0.3\n",
    "TIME_WEIGHT = 0.2\n",
    "\n",
    "# calculate\n",
    "df_competitors_list = []\n",
    "for city in tqdm(cities_list, desc=\"Cities\", position=0):\n",
    "    for property_type in property_types_list:\n",
    "        # get competitors\n",
    "        df_comps = get_competitors(\n",
    "            gdf_properties,\n",
    "            property_type=property_type,\n",
    "            city=city,\n",
    "            batch_size=2_000,\n",
    "            radius=2.5  # search radius in km\n",
    "            )\n",
    "        # append\n",
    "        df_competitors_list.append(df_comps)\n",
    "    \n",
    "# concatenate\n",
    "df_competitors = pd.concat(df_competitors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2: Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see shape\n",
    "df_competitors['num_neighbors'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see shape\n",
    "df_competitors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see shape vs original\n",
    "gdf_properties.query(\"city_cluster.eq(0)\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see competitors with only 1\n",
    "df_competitors.sort_values(by='num_neighbors', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand and separate\n",
    "vars_to_stay = [\n",
    "    'property_id', 'property_type',\n",
    "    'longitude', 'latitude',\n",
    "    'superficie_terreno', 'superficie_construida',\n",
    "    'elevador_cat', 'niveles_cat', 'vida_util_cat',\n",
    "    'recamaras_cat', 'banos_cat', 'estacionamiento_cat',\n",
    "    'fecha_avaluo', 'valor_mercado', 'precio_m2'\n",
    "]\n",
    "\n",
    "(\n",
    "    df_competitors\n",
    "    .query(\"property_id_own.eq('5cc32435a1224836af921c93f0d8cb2a')\")\n",
    "    .explode('neighbors_list')\n",
    "    .assign(\n",
    "        property_id_neighbor=lambda x: x['neighbors_list'].str[0],\n",
    "        total_distance=lambda x: x['neighbors_list'].str[1],\n",
    "    )\n",
    "    .drop(columns=['neighbors_list'])\n",
    "    .sort_values(by='total_distance', ignore_index=True)\n",
    "    # merge info of property_own\n",
    "    .merge(\n",
    "        gdf_properties.loc[:, vars_to_stay],\n",
    "        how='inner',\n",
    "        left_on='property_id_own',\n",
    "        right_on='property_id',\n",
    "        suffixes=('_own', '_neighbor'),\n",
    "    )\n",
    "    .drop(columns=['property_id'])\n",
    "    # merge info of property_neighbor\n",
    "    .merge(\n",
    "        gdf_properties.loc[:, vars_to_stay],\n",
    "        how='inner',\n",
    "        left_on='property_id_neighbor',\n",
    "        right_on='property_id',\n",
    "        suffixes=('_own', '_neighbor'),\n",
    "    )\n",
    "    # sort columns by name\n",
    "    .sort_index(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3: Create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df that maps property_id with index\n",
    "df_properties_map = (\n",
    "    gdf_properties\n",
    "    .loc[:, ['property_id']]\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'property_index'})\n",
    ")\n",
    "df_properties_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to map property_id to index\n",
    "def create_sparse_matrix_in_batches(df, df_indexes, batch_size=1_000):\n",
    "    \"\"\"\n",
    "    Convert a large DataFrame with property IDs and neighbor distances into a sparse matrix in batches.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'property_id_own' and 'neighbors_list' columns.\n",
    "                       'property_id_own' contains item IDs.\n",
    "                       'neighbors_list' contains lists of tuples (neighbor_id, distance).\n",
    "    df_indexes (pd.DataFrame): DataFrame with 'property_id' and 'property_index' columns.\n",
    "                                 'property_id' contains item IDs.\n",
    "                                    'property_index' contains item indices.\n",
    "    batch_size (int): The number of rows to process in each batch.\n",
    "\n",
    "    Returns:\n",
    "    scipy.sparse.csr_matrix: The resulting sparse matrix.\n",
    "    \"\"\"\n",
    "    # Split DataFrame into approximately equal-sized batches\n",
    "    num_batches = df.shape[0] // batch_size\n",
    "    chunks = np.array_split(df, num_batches)\n",
    "\n",
    "    # Initialize lists\n",
    "    # info\n",
    "    row_list = []\n",
    "    col_list = []\n",
    "    data_list = []\n",
    "\n",
    "    # garantize the sparse matrix is square\n",
    "    max_id = df_indexes['property_index'].max()\n",
    "\n",
    "    for chunk in tqdm(chunks, desc=\"Batches\"):\n",
    "        # Expand chunk\n",
    "        exploded_chunk = chunk.explode('neighbors_list').reset_index(drop=True)\n",
    "\n",
    "        # Merge with index map\n",
    "        exploded_chunk_ids = (\n",
    "            exploded_chunk\n",
    "            # property id\n",
    "            .merge(df_indexes, left_on='property_id_own', right_on='property_id')\n",
    "            .loc[:, ['property_index', 'neighbors_list']]\n",
    "            # neighbor id\n",
    "            .assign(\n",
    "                property_id_neighbor=lambda x: x['neighbors_list'].str[0],\n",
    "                total_distance=lambda x: x['neighbors_list'].str[1]\n",
    "            )\n",
    "            .merge(df_indexes, left_on='property_id_neighbor', right_on='property_id', suffixes=('_own', '_neighbor'))\n",
    "            .loc[:, ['property_index_own', 'property_index_neighbor', 'total_distance']]\n",
    "        )\n",
    "\n",
    "        # Extract row indices, column indices, and data values\n",
    "        rows = exploded_chunk_ids['property_index_own'].values\n",
    "        cols = exploded_chunk_ids['property_index_neighbor'].values\n",
    "        distances = exploded_chunk_ids['total_distance'].values\n",
    "\n",
    "        # Append to lists\n",
    "        row_list.append(rows)\n",
    "        col_list.append(cols)\n",
    "        data_list.append(distances)\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    rows = np.concatenate(row_list)\n",
    "    cols = np.concatenate(col_list)\n",
    "    distances = np.concatenate(data_list)\n",
    "\n",
    "    # Create the sparse matrix, garanting it is square\n",
    "    sparse_matrix = sp.csr_matrix((distances, (rows, cols)), shape=(max_id + 1, max_id + 1))\n",
    "\n",
    "    return sparse_matrix\n",
    "\n",
    "# Example usage\n",
    "sparse_matrix_comps = create_sparse_matrix_in_batches(\n",
    "    df=df_competitors,\n",
    "    df_indexes=df_properties_map,\n",
    "    batch_size=10_000\n",
    "    )\n",
    "\n",
    "print(sparse_matrix_comps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see shape\n",
    "sparse_matrix_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many non-zero elements\n",
    "print(f\"Non-zero elements: {sparse_matrix_comps.nnz}\")\n",
    "print(f\"Sparsity: {sparse_matrix_comps.nnz / (sparse_matrix_comps.shape[0] * sparse_matrix_comps.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much memory it uses in MB\n",
    "print(f\"Memory usage: {sparse_matrix_comps.data.nbytes / 1e+6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S4: Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dir_save = \"../../data/misc\"\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "# save to pickle (in order to save lists, because parquet doesnt support lists)\n",
    "df_competitors.to_pickle(f\"{dir_save}/df_competitors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sparse matrix\n",
    "sp.save_npz(f\"{dir_save}/sparse_matrix_competitors.npz\", sparse_matrix_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in matlab format\n",
    "io.savemat(f\"{dir_save}/sparse_matrix_competitors.mat\", {\"sparse_matrix_competitors\": sparse_matrix_comps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Competitors Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1: Define statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics of competitors\n",
    "def competitors_stats(df, col_to_summarize, xi=0.2):\n",
    "    # get normalized weights\n",
    "    weights_unorm = np.exp(-xi * df['total_distance'])\n",
    "    weights = weights_unorm / weights_unorm.sum()\n",
    "    n_neighbors = df.shape[0]\n",
    "    sq_sum_weights = np.sum(weights**2) if n_neighbors > 1 else np.nan\n",
    "\n",
    "    # get col to summarize\n",
    "    x_array = df[col_to_summarize].values\n",
    "\n",
    "    # weighted mean\n",
    "    w_mean = np.sum(x_array * weights)\n",
    "\n",
    "    return pd.Series({\n",
    "        'weighted_mean': w_mean,\n",
    "        'weighted_std': np.sqrt(\n",
    "            # unbiased weighted std (theorem)\n",
    "            (1 / (1 - sq_sum_weights)) * np.sum(weights * (x_array - w_mean)**2)\n",
    "            ),\n",
    "        'mean': np.mean(x_array),\n",
    "        'std': np.std(x_array),\n",
    "        'num_neighbors': n_neighbors,\n",
    "    })\n",
    "\n",
    "\n",
    "def get_info_from_competitors(df, df_info, col_to_summarize, xi=0.2, batch_size=2_000):\n",
    "    # Split DataFrame into approximately equal-sized batches\n",
    "    num_batches = df.shape[0] // batch_size\n",
    "    chunks = np.array_split(df, num_batches)\n",
    "\n",
    "    # Initialize list\n",
    "    df_competitors_info_list = []\n",
    "\n",
    "    for chunk in tqdm(chunks, desc=\"Batches\"):\n",
    "        # Expand chunk\n",
    "        exploded_chunk = chunk.explode('neighbors_list').reset_index(drop=True)\n",
    "\n",
    "        # Merge with info\n",
    "        exploded_chunk = (\n",
    "            exploded_chunk\n",
    "            # neighbor id\n",
    "            .assign(\n",
    "                property_id_neighbor=lambda x: x['neighbors_list'].str[0],\n",
    "                total_distance=lambda x: x['neighbors_list'].str[1]\n",
    "            )\n",
    "            .merge(\n",
    "                df_info.loc[:, ['property_id'] + [col_to_summarize]],\n",
    "                left_on='property_id_neighbor', right_on='property_id',\n",
    "                suffixes=('_own', '_neighbor')\n",
    "            )\n",
    "            .drop(columns=['property_id', 'neighbors_list'])\n",
    "        )\n",
    "\n",
    "        # get stats\n",
    "        df_competitors_info = (\n",
    "            exploded_chunk\n",
    "            .groupby('property_id_own', as_index=False)\n",
    "            .apply(\n",
    "                competitors_stats,\n",
    "                col_to_summarize=col_to_summarize,\n",
    "                xi=xi,\n",
    "                include_groups=False\n",
    "                )\n",
    "        )\n",
    "\n",
    "        # append\n",
    "        df_competitors_info_list.append(df_competitors_info)\n",
    "\n",
    "    # concatenate\n",
    "    df_competitors_info = pd.concat(df_competitors_info_list)\n",
    "\n",
    "    return df_competitors_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from competitors\n",
    "df_competitors_info = get_info_from_competitors(\n",
    "    df=df_competitors,\n",
    "    df_info=gdf_properties,\n",
    "    col_to_summarize='log_price_per_sqm',\n",
    "    xi=5,\n",
    "    batch_size=10_000\n",
    "    )\n",
    "df_competitors_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "df_competitors_info = df_competitors_info.rename(columns={\n",
    "    'weighted_mean': 'competitors_weighted_mean_log_price_per_sqm',\n",
    "    'weighted_std': 'competitors_weighted_std_log_price_per_sqm',\n",
    "    'mean': 'competitors_mean_log_price_per_sqm',\n",
    "    'std': 'competitors_std_log_price_per_sqm',\n",
    "    'num_neighbors': 'num_competitors',\n",
    "})\n",
    "df_competitors_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original data\n",
    "gdf_properties = (\n",
    "    gdf_properties\n",
    "    .merge(\n",
    "        df_competitors_info,\n",
    "        how='left',\n",
    "        left_on='property_id',\n",
    "        right_on='property_id_own',\n",
    "    )\n",
    "    .drop(columns=['property_id_own'])\n",
    ")\n",
    "\n",
    "# shape\n",
    "gdf_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many properties have competitors\n",
    "gdf_properties['num_competitors'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see relationship between log_price_per_sqm and competitors_weighted_mean_log_price_per_sqm\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "(\n",
    "    gdf_properties\n",
    "    .query(\"num_competitors.ge(4)\")\n",
    "    .plot(\n",
    "        x='log_price_per_sqm',\n",
    "        y='competitors_weighted_mean_log_price_per_sqm',\n",
    "        kind='scatter',\n",
    "        ax=ax,\n",
    "        alpha=0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see relationship between log_price_per_sqm and competitors_weighted_mean_log_price_per_sqm\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "(\n",
    "    gdf_properties\n",
    "    .query(\"num_competitors.ge(4)\")\n",
    "    .plot(\n",
    "        x='log_price_per_sqm',\n",
    "        y='competitors_mean_log_price_per_sqm',\n",
    "        kind='scatter',\n",
    "        ax=ax,\n",
    "        alpha=0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see corr between log_price_per_sqm and competitors_weighted_mean_log_price_per_sqm and competitors_mean_log_price_per_sqm\n",
    "(\n",
    "    gdf_properties\n",
    "    .query(\"num_competitors.ge(4)\")\n",
    "    .loc[:, ['log_price_per_sqm', 'competitors_weighted_mean_log_price_per_sqm', 'competitors_mean_log_price_per_sqm']]\n",
    "    .corr(method='spearman')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3: Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "df_competitors_info = df_competitors_info.rename(columns={\n",
    "    'property_id_own': 'property_id'\n",
    "})\n",
    "df_competitors_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dir_save = \"../../data/misc\"\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "# save to parquet\n",
    "df_competitors_info.to_parquet(f\"{dir_save}/df_competitors_stats.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competitors_info.drop(columns='property_id').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop competitors columns\n",
    "gdf_properties.drop(columns=df_competitors_info.drop(columns='property_id').columns, inplace=True)\n",
    "\n",
    "# sort index\n",
    "gdf_properties = gdf_properties.sort_index()\n",
    "\n",
    "# save to parquet\n",
    "gdf_properties.to_parquet(\"../../data/interim/cleaned_data_s6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopper\n",
    "fjasdklf + cdsajofasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdf_neighbors['fecha_avaluo_own'] - gdf_neighbors['fecha_avaluo_neighbor']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_neighbors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with df_competitors\n",
    "(\n",
    "    df_competitors\n",
    "    .merge(\n",
    "        df_properties_map,\n",
    "        how='inner',\n",
    "        left_on='property_id_own',\n",
    "        right_on='property_id',\n",
    "        suffixes=('_comp', '_map')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_properties_work['property_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.96)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_split(np.arange(10), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = []\n",
    "\n",
    "# append\n",
    "aux_list.append(2)\n",
    "\n",
    "aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_properties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.array_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds-research-stay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
